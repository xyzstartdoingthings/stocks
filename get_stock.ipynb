{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Open', 'High', 'Low', 'Adj Close'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fuway\\Desktop\\stocks\\get_stock.ipynb Cell 1\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fuway/Desktop/stocks/get_stock.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# myF.df = myF.df.shift(1).drop([\"Target\", \"Date\", \"Adj Close\"], axis=1).merge(myF.df,left_index = True, right_index = True)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fuway/Desktop/stocks/get_stock.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     data\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mconcat([data, myF\u001b[39m.\u001b[39mdf])\u001b[39m.\u001b[39mdropna()\u001b[39m.\u001b[39msort_values(by \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mBar Time\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fuway/Desktop/stocks/get_stock.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m data\u001b[39m.\u001b[39;49mdrop([\u001b[39m\"\u001b[39;49m\u001b[39mOpen\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mHigh\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mLow\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mAdj Close\u001b[39;49m\u001b[39m\"\u001b[39;49m], inplace \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:5388\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5240\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5241\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5242\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5249\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5250\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5251\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5252\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5386\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5387\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5388\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5389\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5390\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5391\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5392\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5393\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5394\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5395\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5396\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6975\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6973\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6974\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6975\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6976\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6977\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Open', 'High', 'Low', 'Adj Close'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# define the stocks to download\n",
    "from get_stock import createCSV\n",
    "import pandas as pd\n",
    "import talib\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "stocks = [\"MSFT\"]\n",
    "\n",
    "# define the time range for the historical data\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2021-12-31'\n",
    "\n",
    "myF = createCSV()\n",
    "myF.update_time_range(start_date,end_date)\n",
    "data = pd.DataFrame()\n",
    "for stock in stocks:\n",
    "    myF.process_stock(stock)\n",
    "    myF.df = myF.df.shift(1).drop([\"Target\", \"Date\", \"Adj Close\"], axis=1).merge(myF.df,left_index = True, right_index = True)\n",
    "    data=pd.concat([data, myF.df]).dropna().sort_values(by = \"Bar Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Open_x', 'High_x', 'Low_x', 'Close_x', 'Volume_x', 'MACD_x',\n",
    "       'signal_x', 'hist_x', 'k_line_x', 'd_line_x', 'j_line_x', 'rsi_x',\n",
    "       'BBand_high_x', 'BBand_low_x', 'BBand_mid_x', 'sma_5_x', 'sma_10_x',\n",
    "       'sma_30_x', 'sma_60_x', 'ema_5_x', 'ema_10_x', 'ema_30_x', 'ema_60_x',\n",
    "       'Open_y', 'High_y', 'Low_y', 'Close_y', 'Volume_y',\n",
    "       'MACD_y', 'signal_y', 'hist_y', 'k_line_y', 'd_line_y', 'j_line_y',\n",
    "       'rsi_y', 'BBand_high_y', 'BBand_low_y', 'BBand_mid_y', 'sma_5_y',\n",
    "       'sma_10_y', 'sma_30_y', 'sma_60_y', 'ema_5_y', 'ema_10_y', 'ema_30_y',\n",
    "       'ema_60_y']] = scaler.fit_transform(data[['Open_x', 'High_x', 'Low_x', 'Close_x', 'Volume_x', 'MACD_x',\n",
    "       'signal_x', 'hist_x', 'k_line_x', 'd_line_x', 'j_line_x', 'rsi_x',\n",
    "       'BBand_high_x', 'BBand_low_x', 'BBand_mid_x', 'sma_5_x', 'sma_10_x',\n",
    "       'sma_30_x', 'sma_60_x', 'ema_5_x', 'ema_10_x', 'ema_30_x', 'ema_60_x',\n",
    "       'Open_y', 'High_y', 'Low_y', 'Close_y', 'Volume_y',\n",
    "       'MACD_y', 'signal_y', 'hist_y', 'k_line_y', 'd_line_y', 'j_line_y',\n",
    "       'rsi_y', 'BBand_high_y', 'BBand_low_y', 'BBand_mid_y', 'sma_5_y',\n",
    "       'sma_10_y', 'sma_30_y', 'sma_60_y', 'ema_5_y', 'ema_10_y', 'ema_30_y',\n",
    "       'ema_60_y']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fuway\\AppData\\Local\\Temp\\ipykernel_1424\\467551765.py:1: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_train = data.Target[0:int(2/3*len(data))]\n",
      "C:\\Users\\fuway\\AppData\\Local\\Temp\\ipykernel_1424\\467551765.py:2: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_test = data.Target[int(2/3*len(data)):]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_x</th>\n",
       "      <th>High_x</th>\n",
       "      <th>Low_x</th>\n",
       "      <th>Close_x</th>\n",
       "      <th>Volume_x</th>\n",
       "      <th>MACD_x</th>\n",
       "      <th>signal_x</th>\n",
       "      <th>hist_x</th>\n",
       "      <th>k_line_x</th>\n",
       "      <th>d_line_x</th>\n",
       "      <th>...</th>\n",
       "      <th>BBand_low_y</th>\n",
       "      <th>BBand_mid_y</th>\n",
       "      <th>sma_5_y</th>\n",
       "      <th>sma_10_y</th>\n",
       "      <th>sma_30_y</th>\n",
       "      <th>sma_60_y</th>\n",
       "      <th>ema_5_y</th>\n",
       "      <th>ema_10_y</th>\n",
       "      <th>ema_30_y</th>\n",
       "      <th>ema_60_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bar Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.216148</td>\n",
       "      <td>0.429701</td>\n",
       "      <td>0.409002</td>\n",
       "      <td>0.534695</td>\n",
       "      <td>0.050858</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009387</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.002271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.214877</td>\n",
       "      <td>0.427093</td>\n",
       "      <td>0.407693</td>\n",
       "      <td>0.530141</td>\n",
       "      <td>0.021686</td>\n",
       "      <td>0.034161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008946</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.001949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.230355</td>\n",
       "      <td>0.425662</td>\n",
       "      <td>0.406307</td>\n",
       "      <td>0.529349</td>\n",
       "      <td>0.050951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.001589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235223</td>\n",
       "      <td>0.423153</td>\n",
       "      <td>0.404603</td>\n",
       "      <td>0.526104</td>\n",
       "      <td>0.051016</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.248809</td>\n",
       "      <td>0.426779</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.538378</td>\n",
       "      <td>0.199303</td>\n",
       "      <td>0.062753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>0.324997</td>\n",
       "      <td>0.320105</td>\n",
       "      <td>0.326369</td>\n",
       "      <td>0.326432</td>\n",
       "      <td>0.076006</td>\n",
       "      <td>0.490850</td>\n",
       "      <td>0.462691</td>\n",
       "      <td>0.582663</td>\n",
       "      <td>0.672379</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332971</td>\n",
       "      <td>0.326273</td>\n",
       "      <td>0.328133</td>\n",
       "      <td>0.326101</td>\n",
       "      <td>0.325802</td>\n",
       "      <td>0.335424</td>\n",
       "      <td>0.326385</td>\n",
       "      <td>0.327289</td>\n",
       "      <td>0.329016</td>\n",
       "      <td>0.330350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>0.328710</td>\n",
       "      <td>0.323536</td>\n",
       "      <td>0.321211</td>\n",
       "      <td>0.320620</td>\n",
       "      <td>0.174862</td>\n",
       "      <td>0.484717</td>\n",
       "      <td>0.464298</td>\n",
       "      <td>0.559970</td>\n",
       "      <td>0.469768</td>\n",
       "      <td>0.615582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333794</td>\n",
       "      <td>0.326887</td>\n",
       "      <td>0.328693</td>\n",
       "      <td>0.327191</td>\n",
       "      <td>0.325888</td>\n",
       "      <td>0.335640</td>\n",
       "      <td>0.327370</td>\n",
       "      <td>0.327964</td>\n",
       "      <td>0.329420</td>\n",
       "      <td>0.330729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>0.319311</td>\n",
       "      <td>0.321173</td>\n",
       "      <td>0.318401</td>\n",
       "      <td>0.327158</td>\n",
       "      <td>0.109204</td>\n",
       "      <td>0.487763</td>\n",
       "      <td>0.466305</td>\n",
       "      <td>0.564064</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334889</td>\n",
       "      <td>0.327563</td>\n",
       "      <td>0.327673</td>\n",
       "      <td>0.327871</td>\n",
       "      <td>0.326520</td>\n",
       "      <td>0.335814</td>\n",
       "      <td>0.328226</td>\n",
       "      <td>0.328626</td>\n",
       "      <td>0.329838</td>\n",
       "      <td>0.331116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>0.325687</td>\n",
       "      <td>0.321885</td>\n",
       "      <td>0.326369</td>\n",
       "      <td>0.327752</td>\n",
       "      <td>0.078489</td>\n",
       "      <td>0.490562</td>\n",
       "      <td>0.468574</td>\n",
       "      <td>0.566744</td>\n",
       "      <td>0.450886</td>\n",
       "      <td>0.437836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334808</td>\n",
       "      <td>0.327497</td>\n",
       "      <td>0.326532</td>\n",
       "      <td>0.328009</td>\n",
       "      <td>0.326981</td>\n",
       "      <td>0.335830</td>\n",
       "      <td>0.326782</td>\n",
       "      <td>0.328058</td>\n",
       "      <td>0.329827</td>\n",
       "      <td>0.331281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>0.328020</td>\n",
       "      <td>0.322468</td>\n",
       "      <td>0.320451</td>\n",
       "      <td>0.321775</td>\n",
       "      <td>0.117777</td>\n",
       "      <td>0.484954</td>\n",
       "      <td>0.469060</td>\n",
       "      <td>0.548506</td>\n",
       "      <td>0.455022</td>\n",
       "      <td>0.432631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334906</td>\n",
       "      <td>0.327695</td>\n",
       "      <td>0.326459</td>\n",
       "      <td>0.328917</td>\n",
       "      <td>0.327310</td>\n",
       "      <td>0.335946</td>\n",
       "      <td>0.327267</td>\n",
       "      <td>0.328391</td>\n",
       "      <td>0.330106</td>\n",
       "      <td>0.331591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open_x    High_x     Low_x   Close_x  Volume_x    MACD_x  \\\n",
       "Bar Time                                                               \n",
       "60        0.002498  0.002590  0.003934  0.002213  0.216148  0.429701   \n",
       "61        0.001446  0.000939  0.002711  0.001222  0.214877  0.427093   \n",
       "62        0.000854  0.000065  0.001951  0.001420  0.230355  0.425662   \n",
       "63        0.001052  0.000000  0.001322  0.000000  0.235223  0.423153   \n",
       "64        0.000000  0.003366  0.001521  0.004161  0.248809  0.426779   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "1189      0.324997  0.320105  0.326369  0.326432  0.076006  0.490850   \n",
       "1190      0.328710  0.323536  0.321211  0.320620  0.174862  0.484717   \n",
       "1191      0.319311  0.321173  0.318401  0.327158  0.109204  0.487763   \n",
       "1192      0.325687  0.321885  0.326369  0.327752  0.078489  0.490562   \n",
       "1193      0.328020  0.322468  0.320451  0.321775  0.117777  0.484954   \n",
       "\n",
       "          signal_x    hist_x  k_line_x  d_line_x  ...  BBand_low_y  \\\n",
       "Bar Time                                          ...                \n",
       "60        0.409002  0.534695  0.050858  0.181888  ...     0.009387   \n",
       "61        0.407693  0.530141  0.021686  0.034161  ...     0.008946   \n",
       "62        0.406307  0.529349  0.050951  0.000000  ...     0.008342   \n",
       "63        0.404603  0.526104  0.051016  0.000056  ...     0.008289   \n",
       "64        0.404100  0.538378  0.199303  0.062753  ...     0.008375   \n",
       "...            ...       ...       ...       ...  ...          ...   \n",
       "1189      0.462691  0.582663  0.672379  0.688872  ...     0.332971   \n",
       "1190      0.464298  0.559970  0.469768  0.615582  ...     0.333794   \n",
       "1191      0.466305  0.564064  0.443205  0.516021  ...     0.334889   \n",
       "1192      0.468574  0.566744  0.450886  0.437836  ...     0.334808   \n",
       "1193      0.469060  0.548506  0.455022  0.432631  ...     0.334906   \n",
       "\n",
       "          BBand_mid_y   sma_5_y  sma_10_y  sma_30_y  sma_60_y   ema_5_y  \\\n",
       "Bar Time                                                                  \n",
       "60           0.001426  0.001107  0.002664  0.002979  0.004147  0.001260   \n",
       "61           0.001028  0.000614  0.002065  0.002659  0.003817  0.000791   \n",
       "62           0.000550  0.000000  0.001393  0.002294  0.003502  0.000000   \n",
       "63           0.000412  0.000387  0.000945  0.002032  0.003227  0.000876   \n",
       "64           0.000188  0.000767  0.000498  0.001734  0.002871  0.001437   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "1189         0.326273  0.328133  0.326101  0.325802  0.335424  0.326385   \n",
       "1190         0.326887  0.328693  0.327191  0.325888  0.335640  0.327370   \n",
       "1191         0.327563  0.327673  0.327871  0.326520  0.335814  0.328226   \n",
       "1192         0.327497  0.326532  0.328009  0.326981  0.335830  0.326782   \n",
       "1193         0.327695  0.326459  0.328917  0.327310  0.335946  0.327267   \n",
       "\n",
       "          ema_10_y  ema_30_y  ema_60_y  \n",
       "Bar Time                                \n",
       "60        0.001171  0.001583  0.002271  \n",
       "61        0.000672  0.001205  0.001949  \n",
       "62        0.000000  0.000755  0.001589  \n",
       "63        0.000223  0.000614  0.001386  \n",
       "64        0.000392  0.000477  0.001188  \n",
       "...            ...       ...       ...  \n",
       "1189      0.327289  0.329016  0.330350  \n",
       "1190      0.327964  0.329420  0.330729  \n",
       "1191      0.328626  0.329838  0.331116  \n",
       "1192      0.328058  0.329827  0.331281  \n",
       "1193      0.328391  0.330106  0.331591  \n",
       "\n",
       "[1134 rows x 46 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = data.Target[0:int(2/3*len(data))]\n",
    "y_test = data.Target[int(2/3*len(data)):]\n",
    "X_train = data.drop([\"Target\", \"Date\", \"Adj Close\"], axis=1)[0:int(2/3*len(data))]\n",
    "X_test = data.drop([\"Target\", \"Date\", \"Adj Close\"], axis=1)[int(2/3*len(data)):]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    567\n",
       "1.0    312\n",
       "2.0    255\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2535211267605634\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.55      0.38       216\n",
      "         1.0       0.00      0.00      0.00       192\n",
      "         2.0       0.17      0.16      0.16       160\n",
      "\n",
      "    accuracy                           0.25       568\n",
      "   macro avg       0.15      0.24      0.18       568\n",
      "weighted avg       0.16      0.25      0.19       568\n",
      "\n",
      "Accuracy: 0.29225352112676056\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       216\n",
      "         1.0       0.55      0.09      0.15       192\n",
      "         2.0       0.28      0.93      0.43       160\n",
      "\n",
      "    accuracy                           0.29       568\n",
      "   macro avg       0.28      0.34      0.19       568\n",
      "weighted avg       0.26      0.29      0.17       568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fuway\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fuway\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fuway\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_proba = rf.predict_proba(X_test)\n",
    "y_pred_weighted = []\n",
    "for i in range(len(y_pred)):\n",
    "    if max(y_proba[i]) >=0.8:\n",
    "        y_pred_weighted.append(y_pred[i])\n",
    "    else:\n",
    "        y_pred_weighted.append(0)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_weighted))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_weighted))\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = []\n",
    "for i in y_train:\n",
    "    if i == 0:\n",
    "        sample_weights.append(1)\n",
    "    elif i==1:\n",
    "        sample_weights.append(20)\n",
    "    else:\n",
    "        sample_weights.append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28169014084507044\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.23      0.01      0.03       216\n",
      "         1.0       0.50      0.01      0.02       192\n",
      "         2.0       0.28      0.97      0.44       160\n",
      "\n",
      "    accuracy                           0.28       568\n",
      "   macro avg       0.34      0.33      0.16       568\n",
      "weighted avg       0.34      0.28      0.14       568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# For classification problems\n",
    "xgb = xgb.XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_proba = xgb.predict_proba(X_test)\n",
    "y_pred_weighted = []\n",
    "for i in range(len(y_pred)):\n",
    "    if max(y_proba[i]) >=0.7:\n",
    "        y_pred_weighted.append(y_pred[i])\n",
    "    else:\n",
    "        y_pred_weighted.append(0)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_weighted))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1620 candidates, totalling 4860 fits\n",
      "[22:11:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"max_leaf_nodes\" } are not used.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective=&#x27;multi:softprob&#x27;, predictor=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.5, 0.8, 1.0],\n",
       "                         &#x27;eta&#x27;: [0.1, 0.2, 0.4], &#x27;gamma&#x27;: [0, 0.2, 0.4],\n",
       "                         &#x27;lambda&#x27;: [0.5, 1, 2], &#x27;max_depth&#x27;: [3, 5, 10, 20],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [2, 4, 8, 16, 32]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective=&#x27;multi:softprob&#x27;, predictor=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.5, 0.8, 1.0],\n",
       "                         &#x27;eta&#x27;: [0.1, 0.2, 0.4], &#x27;gamma&#x27;: [0, 0.2, 0.4],\n",
       "                         &#x27;lambda&#x27;: [0.5, 1, 2], &#x27;max_depth&#x27;: [3, 5, 10, 20],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [2, 4, 8, 16, 32]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective='multi:softprob', predictor=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.8, 1.0],\n",
       "                         'eta': [0.1, 0.2, 0.4], 'gamma': [0, 0.2, 0.4],\n",
       "                         'lambda': [0.5, 1, 2], 'max_depth': [3, 5, 10, 20],\n",
       "                         'max_leaf_nodes': [2, 4, 8, 16, 32]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, 20],\n",
    "    'max_leaf_nodes': [2,4, 8, 16, 32],\n",
    "    'gamma': [0, 0.2, 0.4],\n",
    "    'eta': [0.1, 0.2, 0.4],\n",
    "    'colsample_bytree': [0.5, 0.8, 1.0],\n",
    "    'lambda': [0.5, 1, 2]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train, sample_weight = sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29401408450704225\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.04      0.08       216\n",
      "         1.0       0.60      0.02      0.03       192\n",
      "         2.0       0.29      0.97      0.44       160\n",
      "\n",
      "    accuracy                           0.29       568\n",
      "   macro avg       0.44      0.34      0.18       568\n",
      "weighted avg       0.45      0.29      0.16       568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "y_proba = grid_search.best_estimator_.predict_proba(X_test)\n",
    "y_pred_weighted = []\n",
    "for i in range(len(y_pred)):\n",
    "    if max(y_proba[i]) >=0.5:\n",
    "        y_pred_weighted.append(y_pred[i])\n",
    "    else:\n",
    "        y_pred_weighted.append(0)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_weighted))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as', 'b']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall(r\"[a-zA-Z0-9]+\", \"as_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9023569023569024\n"
     ]
    }
   ],
   "source": [
    "def jaro_similarity(s1, s2):\n",
    "    s1_len = len(s1)\n",
    "    s2_len = len(s2)\n",
    "\n",
    "    if s1_len == 0 and s2_len == 0:\n",
    "        return 1\n",
    "\n",
    "    match_distance = (max(s1_len, s2_len) // 2) - 1\n",
    "    s1_matches = [False] * s1_len\n",
    "    s2_matches = [False] * s2_len\n",
    "\n",
    "    matches = 0\n",
    "    transpositions = 0\n",
    "\n",
    "    for i in range(s1_len):\n",
    "        start = max(0, i - match_distance)\n",
    "        end = min(i + match_distance + 1, s2_len)\n",
    "\n",
    "        for j in range(start, end):\n",
    "            if s2_matches[j]:\n",
    "                continue\n",
    "            if s1[i] != s2[j]:\n",
    "                continue\n",
    "\n",
    "            s1_matches[i] = True\n",
    "            s2_matches[j] = True\n",
    "            matches += 1\n",
    "            break\n",
    "\n",
    "    if matches == 0:\n",
    "        return 0\n",
    "\n",
    "    k = 0\n",
    "    for i in range(s1_len):\n",
    "        if not s1_matches[i]:\n",
    "            continue\n",
    "\n",
    "        while not s2_matches[k]:\n",
    "            k += 1\n",
    "\n",
    "        if s1[i] != s2[k]:\n",
    "            transpositions += 1\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    return ((matches / s1_len) + (matches / s2_len) + ((matches - transpositions / 2) / matches)) / 3\n",
    "\n",
    "\n",
    "def jaro_winkler_similarity(s1, s2, p=0.1):\n",
    "    jaro_sim = jaro_similarity(s1, s2)\n",
    "\n",
    "    prefix_len = 0\n",
    "    for i in range(min(len(s1), len(s2))):\n",
    "        if s1[i] == s2[i]:\n",
    "            prefix_len += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return jaro_sim + (prefix_len * p * (1 - jaro_sim))\n",
    "\n",
    "\n",
    "word1 = \"Australia\"\n",
    "word2 = \"Australasia\"\n",
    "\n",
    "similarity = jaro_similarity(word1, word2)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
